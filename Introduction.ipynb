{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "Introduction.ipynb",
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dixiong777/DL_Pytorch/blob/master/Introduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22sDZlClGYn9"
      },
      "source": [
        "##  Introduction\n",
        "Reference: https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#sphx-glr-beginner-blitz-tensor-tutorial-py\n",
        "\n",
        "Minor changes for self learning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MKJvkSMGYoF"
      },
      "source": [
        "# Other useful packages\n",
        "import timeit\n",
        "from __future__ import print_function\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyghDzyFGYoG"
      },
      "source": [
        "### 1. Pytorch v.s. Numpy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLsuP_foGYoG"
      },
      "source": [
        "import torch\n",
        "x = torch.rand(5, 3)\n",
        "print(x)\n",
        "timeit.timeit(lambda: torch.rand(5, 3), number=10000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUjeUNcmGYoH"
      },
      "source": [
        "import numpy\n",
        "y = numpy.random.rand(5, 3)\n",
        "print(y)\n",
        "timeit.timeit(lambda: numpy.random.rand(5, 3), number=10000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ly3SuwPTGYoH"
      },
      "source": [
        "### 2. Generate a Matrix\n",
        "\n",
        "#### Empty Matrix\n",
        "An uninitialized matrix is declared, but does not contain definite known values before it is used. When an uninitialized matrix is created, whatever values were in the allocated memory at the time will appear as the initial values.\n",
        "\n",
        "#### Random Matrix\n",
        "Use `torch.manual_seed(0)` to set seed instead of `random.rand(0)`.\n",
        "\n",
        "#### Zero Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFvKuB3tGYoI"
      },
      "source": [
        "# Empty Matrix: Results can be different even with a specific seed.\n",
        "torch.manual_seed(0)\n",
        "x = torch.empty(5, 3)\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fS49SYVtGYoI"
      },
      "source": [
        "# Random Matrix:\n",
        "torch.manual_seed(0)\n",
        "x = torch.rand(5, 3)\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q279497dGYoI"
      },
      "source": [
        "# Zero Matrix: If not specific type, it will be float.\n",
        "x = torch.zeros(5, 3, dtype = torch.long)\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9D01S5p0GYoJ"
      },
      "source": [
        "### 3. Create a tensor\n",
        "Tensors are similar to NumPyâ€™s ndarrays, with the addition being that Tensors can also be used on a GPU to accelerate computing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mi6w96xBGYoJ"
      },
      "source": [
        "# Create a new tensor\n",
        "x = torch.tensor([5.5, 3])\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QY1yWL9AGYoJ"
      },
      "source": [
        "# Generate from an existing tensor.\n",
        "# Default toch.dtype and torch.device are same as that of x.\n",
        "y = x.new_ones(5, 3, dtype = torch.double)\n",
        "print(y)\n",
        "print(y.size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FY74fsk-GYoK"
      },
      "source": [
        "# Override dtype and values but with the same size of y\n",
        "# randomn - from a normal distribution. \n",
        "z = torch.randn_like(y, dtype = torch.float)\n",
        "print(z)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyebAQ9xGYoK"
      },
      "source": [
        "# Size\n",
        "# torch.Size() is a tuple (a row of record) so it supports all tuple operations.\n",
        "print(z.size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Y7Tn1g7GYoK"
      },
      "source": [
        "### 4. Operations\n",
        "\n",
        "* Any operation that mutates a tensor in-place is post-fixed with an _. For example: x.copy_(y), x.t_(), will change x.\n",
        "\n",
        "* More Operations are avaliable here [https://pytorch.org/docs/stable/torch.html]\n",
        "    1. Tensors\n",
        "    2. Generators\n",
        "    3. Random Sampling\n",
        "    4. Serialization\n",
        "    5. Parallelism\n",
        "    6. Locally Disabling Gradient Computation\n",
        "    7. Match Operations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCNBQkVvGYoK"
      },
      "source": [
        "# Addition:\n",
        "x = torch.rand(5, 3)\n",
        "y = torch.rand(5, 3)\n",
        "print('x = ', x)\n",
        "print('y = ', y)\n",
        "\n",
        "## Direct way:\n",
        "print('x + y =', x + y)\n",
        "\n",
        "## Function:\n",
        "print('x + y = ', torch.add(x, y))\n",
        "\n",
        "## Store the result.\n",
        "result = torch.empty(5, 3)\n",
        "print('x + y = ', torch.add(x, y, out = result))\n",
        "print('Stored result is', result)\n",
        "\n",
        "## Function on one of the variable:\n",
        "print('Add x to y:', y.add_(x))\n",
        "print('And the y will be updated as', y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYmWUUVMGYoL"
      },
      "source": [
        "### 5. Index\n",
        "Similiar to the Numpy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0_ITt8yGYoL"
      },
      "source": [
        "print(x[:, 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ye2ec2qVGYoL"
      },
      "source": [
        "# If only one element, we can view it as a Python number using x.item()\n",
        "# Will be error if more than one element.\n",
        "x = torch.randn(1)\n",
        "print(x)\n",
        "print(x.item())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cu-uBYGFGYoL"
      },
      "source": [
        "###  6. Reshape and Resize:\n",
        "\n",
        "* torch.view()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Zl-fQMPGYoM"
      },
      "source": [
        "# Generate x from a standard normal distribution\n",
        "x = torch.randn(4, 4)\n",
        "print(x)\n",
        "\n",
        "# Reshape to 2 * 8 matrix instead.\n",
        "y = x.view(2, 8)\n",
        "print(y)\n",
        "\n",
        "# Automatically calculate the other dimension. \n",
        "z = x.view(-1, 16)\n",
        "print(z)\n",
        "\n",
        "# Print all sizes:\n",
        "print('size of x:', x.size())\n",
        "print('size of y:', y.size())\n",
        "print('size of z:', z.size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDTlHU7rGYoM"
      },
      "source": [
        "### 7. Transfer to and from a Numpy array\n",
        "\n",
        "* The Torch Tensor and NumPy array will share their underlying memory locations (if the Torch Tensor is on CPU), and changing one will change the other.\n",
        "\n",
        "* All the Tensors on the CPU except for the CharTensor support converting to NumPy and back."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cc7lqSk5GYoM"
      },
      "source": [
        "# Converting a Torch Tensor to a Numpy Array\n",
        "a = torch.ones(5)\n",
        "print(a)\n",
        "\n",
        "b = a.numpy()\n",
        "print(b)\n",
        "\n",
        "# If change on a, b will be changed as well.\n",
        "a.add_(1)\n",
        "print('After changing, a = ', a)\n",
        "print('After changing, b = ', b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "km1l4ZAEGYoN"
      },
      "source": [
        "# Converting a Numpy Array to a Torch Tensor\n",
        "import numpy as np\n",
        "a = np.ones(5)\n",
        "print(a)\n",
        "b = torch.from_numpy(a)\n",
        "print(b)\n",
        "\n",
        "# If change on a, b will be changed as well.\n",
        "np.add(a, 1, out = a)\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3xF8vgkGYoN"
      },
      "source": [
        "### 8. CUDA Tensors\n",
        "\n",
        "* Can move the tensors in and out of GPU using the `.to` method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1o-nxesGYoN"
      },
      "source": [
        "# Check whether CUDA is avaliable:\n",
        "torch.cuda.is_available()\n",
        "\n",
        "# Check the name of CUA\n",
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydS2_4J4GYoN"
      },
      "source": [
        "# Move the tensors to the CUDA\n",
        "# No CUDA support on the Mac....\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "    # Directly create a tensor on GPU\n",
        "    y = torch.ones_like(x, device = device)\n",
        "    # Move the tensor to GPU\n",
        "    x = x.to(device)\n",
        "    z = x + y\n",
        "    print(z)\n",
        "    \n",
        "    # Move back to CPU\n",
        "    print(z.to('cpu', torch.double))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}